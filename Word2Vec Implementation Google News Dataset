{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sapnachokshi/word2vec-sample-implementation?scriptVersionId=186575471\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"0cb5f089","metadata":{"execution":{"iopub.execute_input":"2024-07-02T18:18:12.56331Z","iopub.status.busy":"2024-07-02T18:18:12.562221Z","iopub.status.idle":"2024-07-02T18:18:28.594486Z","shell.execute_reply":"2024-07-02T18:18:28.592712Z"},"papermill":{"duration":16.041229,"end_time":"2024-07-02T18:18:28.597129","exception":false,"start_time":"2024-07-02T18:18:12.5559","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# Import necessary libraries\n","from gensim.models import KeyedVectors\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import nltk\n","import pandas as pd\n","import numpy as np\n","import os \n","\n","# Download necessary NLTK data\n","nltk.download('punkt')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":2,"id":"9bb588d1","metadata":{"execution":{"iopub.execute_input":"2024-07-02T18:18:28.607442Z","iopub.status.busy":"2024-07-02T18:18:28.606587Z","iopub.status.idle":"2024-07-02T18:19:55.290411Z","shell.execute_reply":"2024-07-02T18:19:55.288949Z"},"papermill":{"duration":86.692425,"end_time":"2024-07-02T18:19:55.293531","exception":false,"start_time":"2024-07-02T18:18:28.601106","status":"completed"},"tags":[]},"outputs":[],"source":["# Path to the Google News vectors dataset in Kaggle environment\n","model_path = '/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin'\n","\n","# Load the pre-trained Word2Vec model\n","model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n","\n","# Test the model - Words most similar \n","#if 'sample' in model.key_to_index:\n","#    similar_words = model.most_similar('sample')\n","#    print(\"Words similar to 'sample':\", similar_words)\n","\n","# Get the vector for a word\n","#if 'sample' in model.key_to_index:\n","#    word_vector = model['sample']\n","#    print(\"Vector for 'sample':\", word_vector)"]},{"cell_type":"code","execution_count":3,"id":"68fdf452","metadata":{"execution":{"iopub.execute_input":"2024-07-02T18:19:55.30318Z","iopub.status.busy":"2024-07-02T18:19:55.302739Z","iopub.status.idle":"2024-07-02T18:19:55.311057Z","shell.execute_reply":"2024-07-02T18:19:55.309606Z"},"papermill":{"duration":0.016026,"end_time":"2024-07-02T18:19:55.313676","exception":false,"start_time":"2024-07-02T18:19:55.29765","status":"completed"},"tags":[]},"outputs":[],"source":["#define function to get compound vector if needed \n","def get_compound_vector(word2vec_model, compound_word):\n","        words = compound_word.replace('-',' ').split()\n","        word_vectors = [word2vec_model[word] for word in words if word in word2vec_model]\n","        \n","        if not word_vectors:\n","                return None #None of the words in the compound word are in corpora\n","        compound_vector = np.mean(word_vectors, axis = 0)\n","        return compound_vector "]},{"cell_type":"code","execution_count":4,"id":"fe0220f9","metadata":{"execution":{"iopub.execute_input":"2024-07-02T18:19:55.32352Z","iopub.status.busy":"2024-07-02T18:19:55.323002Z","iopub.status.idle":"2024-07-02T18:19:55.397702Z","shell.execute_reply":"2024-07-02T18:19:55.396379Z"},"papermill":{"duration":0.082765,"end_time":"2024-07-02T18:19:55.400334","exception":false,"start_time":"2024-07-02T18:19:55.317569","status":"completed"},"tags":[]},"outputs":[],"source":["# Function to compute similarity between two words\n","def compute_similarity(word1, word2):\n","    if word1 in model.key_to_index and word2 in model.key_to_index:\n","        similarity = model.similarity(word1, word2)\n","        return similarity\n","    else:\n","        vector1 = get_compound_vector(model, word1) if word1 not in model.key_to_index else model[word1]\n","        vector2 = get_compound_vector(model, word2) if word2 not in model.key_to_index else model[word2]\n","        if vector1 is not None and vector2 is not None:\n","            similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n","            return similarity \n","        else:\n","            missing_words = [word for word in [word1, word2] if word not in model.key_to_index and get_compound_vector(model, word) is None]\n","            return f\"Word(s) not in vocabulary: {', '.join(missing_words)}\""]},{"cell_type":"code","execution_count":5,"id":"5164bc0c","metadata":{"execution":{"iopub.execute_input":"2024-07-02T18:19:55.409631Z","iopub.status.busy":"2024-07-02T18:19:55.409248Z","iopub.status.idle":"2024-07-02T18:19:55.415675Z","shell.execute_reply":"2024-07-02T18:19:55.414488Z"},"papermill":{"duration":0.014045,"end_time":"2024-07-02T18:19:55.418191","exception":false,"start_time":"2024-07-02T18:19:55.404146","status":"completed"},"tags":[]},"outputs":[],"source":["# Specify the indiviudal input file paths\n","input_file_paths = [\n","    '/kaggle/input/actions-and-agents-datasets/actions_and_distractors_output.csv',  # Update this path\n","    '/kaggle/input/actions-and-agents-datasets/agents_and_distractors_output.csv'  # Update this path\n","]\n","\n","# Specify the corresponding output file names\n","output_file_names = [\n","    'output_actions_similarity_scores.csv',\n","    'output_agents_similairity_scores.csv'\n","]"]},{"cell_type":"code","execution_count":6,"id":"53fa3555","metadata":{"execution":{"iopub.execute_input":"2024-07-02T18:19:55.427407Z","iopub.status.busy":"2024-07-02T18:19:55.426938Z","iopub.status.idle":"2024-07-02T18:19:55.575232Z","shell.execute_reply":"2024-07-02T18:19:55.573613Z"},"papermill":{"duration":0.156506,"end_time":"2024-07-02T18:19:55.578562","exception":false,"start_time":"2024-07-02T18:19:55.422056","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Results for actions_and_distractors_output.csv saved to output_actions_similarity_scores.csv:\n","            word1       word2  similarity\n","0          Target  Action cue    0.178605\n","1    baby-clothes      change    0.125733\n","2    baby-clothes     launder    0.204648\n","3    baby-clothes       dress    0.477588\n","4    baby-clothes        wash    0.294477\n","..            ...         ...         ...\n","755        window    insulate    0.116420\n","756        window       cover    0.111925\n","757        window   reinforce    0.057874\n","758        window        look    0.131642\n","759        window        peer    0.105550\n","\n","[760 rows x 3 columns]\n","Results for agents_and_distractors_output.csv saved to output_agents_similairity_scores.csv:\n","            word1      word2 similarity\n","0          Target  Agent cue    0.08672\n","1    baby-clothes     infant   0.620417\n","2    baby-clothes      nanny   0.339819\n","3    baby-clothes     mother   0.520415\n","4    baby-clothes     parent   0.200806\n","..            ...        ...        ...\n","549        window  decorator   0.143647\n","550        window     viewer   0.183931\n","551        window   resident   0.065734\n","552        window    glazier   0.272855\n","553        window   designer    0.02201\n","\n","[554 rows x 3 columns]\n"]}],"source":["# Process each input file individually\n","for input_file_path, output_file_name in zip(input_file_paths, output_file_names):\n","    # Read the CSV file into a DataFrame, specifying only the first two columns\n","    df = pd.read_csv(input_file_path, usecols=[0, 1], names=['word1', 'word2'])\n","    \n","    # Ensure the DataFrame has the correct columns\n","    if 'word1' not in df.columns or 'word2' not in df.columns:\n","        raise ValueError(\"CSV file must contain 'word1' and 'word2' columns\")\n","\n","    # Create a new column to store the similarity results\n","    df['similarity'] = df.apply(lambda row: compute_similarity(row['word1'], row['word2']), axis=1)\n","    \n","    # Save the results to a new CSV file with the desired name\n","    output_csv_file_path = os.path.join('/kaggle/working', output_file_name)  # Update this path if needed\n","    df.to_csv(output_csv_file_path, index=False)\n","    \n","    # Print a sample of the results\n","    print(f\"Results for {os.path.basename(input_file_path)} saved to {output_file_name}:\")\n","    print(df)"]},{"cell_type":"markdown","id":"84bc60f8","metadata":{"papermill":{"duration":0.003936,"end_time":"2024-07-02T18:19:55.58702","exception":false,"start_time":"2024-07-02T18:19:55.583084","status":"completed"},"tags":[]},"source":["Notes for future implementation: \n","- make sure that target, action cue row of data tables not in the word2vec analyzed area \n","- "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6763,"sourceId":9801,"sourceType":"datasetVersion"},{"datasetId":5050052,"sourceId":8469579,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":108.338067,"end_time":"2024-07-02T18:19:57.422444","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-02T18:18:09.084377","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}