{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9801,"sourceType":"datasetVersion","datasetId":6763},{"sourceId":8469579,"sourceType":"datasetVersion","datasetId":5050052}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nfrom gensim.models import KeyedVectors\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport nltk\nimport pandas as pd\nimport numpy as np\nimport os \n\n# Download necessary NLTK data\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Path to the Google News vectors dataset in Kaggle environment\nmodel_path = '/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin'\n\n# Load the pre-trained Word2Vec model\nmodel = KeyedVectors.load_word2vec_format(model_path, binary=True)\n\n# Test the model - Words most similar \n#if 'sample' in model.key_to_index:\n#    similar_words = model.most_similar('sample')\n#    print(\"Words similar to 'sample':\", similar_words)\n\n# Get the vector for a word\n#if 'sample' in model.key_to_index:\n#    word_vector = model['sample']\n#    print(\"Vector for 'sample':\", word_vector)\n\ndef create_compound_vector(word):\n    if '-' in word:\n        parts = word.split('-')\n        if all(part in model.key_to_index for part in parts):\n            vector = np.mean([model[part] for part in parts], axis=0)\n            model.add_vector(word, vector)\n            return True\n    return False\n\n# Function to compute similarity between two words\ndef compute_similarity(word1, word2):\n    if word1 not in model.key_to_index:\n        if not create_compound_vector(word1):\n            return float('nan')  # Return NaN if the word or its components are not in the model\n    if word2 not in model.key_to_index:\n        if not create_compound_vector(word2):\n            return float('nan')  # Return NaN if the word or its components are not in the model\n    return model.similarity(word1, word2)\n  \n# Specify the individual input file paths\ninput_file_paths = [\n    '/kaggle/input/action-and-agent-outputs/actions_and_distractors_output.csv',  # Update this path\n    '/kaggle/input/action-and-agent-outputs/agents_and_distractors_output.csv'  # Update this path\n]\n\n# Specify the corresponding output file names\noutput_file_names = [\n    'output_actions_similarity_scores.csv',\n    'output_agents_similairity_scores.csv'\n]\n\n# Process each input file individually\nfor input_file_path, output_file_name in zip(input_file_paths, output_file_names):\n    # Read the CSV file into a DataFrame, specifying only the first two columns\n    df = pd.read_csv(input_file_path, usecols=[0, 1], names=['word1', 'word2'])\n    \n    # Ensure the DataFrame has the correct columns\n    if 'word1' not in df.columns or 'word2' not in df.columns:\n        raise ValueError(\"CSV file must contain 'word1' and 'word2' columns\")\n\n    # Create a new column to store the similarity results\n    df['similarity'] = df.apply(lambda row: compute_similarity(row['word1'], row['word2']), axis=1)\n    \n    # Save the results to a new CSV file with the desired name\n    output_csv_file_path = os.path.join('/kaggle/working', output_file_name)  # Update this path if needed\n    df.to_csv(output_csv_file_path, index=False)\n    \n    # Print a sample of the results\n    print(f\"Results for {os.path.basename(input_file_path)} saved to {output_file_name}:\")\n    print(df.head())\n\n# Example usage\n#compute_similarity('nanny', 'infant')\n#compute_similarity('king', 'queen')\n#compute_similarity('car', 'bicycle')","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:00:21.932672Z","iopub.execute_input":"2024-05-20T18:00:21.933439Z"}},"execution_count":null,"outputs":[]}]}